{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d77d6097-8dc3-474b-87bf-7ff2e00c2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54ce0cdc-43e3-4fae-84e4-37ab4236531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables \n",
    "train_csv = \"train.csv\" # replace with your own train label file path\n",
    "val_csv   = \"val.csv\" # replace with your own validation label file path\n",
    "test_csv  = \"offsite_test.csv\"  # replace with your own test label file path\n",
    "train_image_dir =\"./images/train\"   # replace with your own train image floder path\n",
    "val_image_dir = \"./images/val\"  # replace with your own validation image floder path\n",
    "test_image_dir = \"./images/offsite_test\" # replace with your own test image floder path\n",
    "#pretrained_backbone = './pretrained_backbone/ckpt_resnet18_ep50.pt'  # replace with your own pretrained backbone path\n",
    "pretrained_backbone = './pretrained_backbone/ckpt_efficientnet_ep50.pt'\n",
    "#backbone = 'resnet18'  # backbone choices: [\"resnet18\", \"efficientnet\"]\n",
    "backbone = 'efficientnet'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a2e66-d0b4-4203-89f5-529360faa5ee",
   "metadata": {},
   "source": [
    "## Dataset preparation methods from template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bd191c0-5c92-41cb-b196-07d3e62d2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Dataset preparation\n",
    "# ========================\n",
    "class RetinaMultiLabelDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            row = self.data.iloc[idx]\n",
    "            img_path = os.path.join(self.image_dir, row.iloc[0])\n",
    "    \n",
    "            # check if file exists\n",
    "            if not os.path.exists(img_path):\n",
    "                raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "                \n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, labels\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "166f3e32-9742-4fc3-a810-a53105a8e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# build model\n",
    "# ========================\n",
    "def build_model(backbone=\"resnet18\", num_classes=3, pretrained=True):\n",
    "\n",
    "    if(pretrained):\n",
    "        weights_resnet = models.ResNet18_Weights.DEFAULT\n",
    "        weights_efficient_net = models.EfficientNet_B0_Weights.DEFAULT\n",
    "    else:\n",
    "        weights_resnet = weights_efficient_net = None\n",
    "\n",
    "    if backbone == \"resnet18\":\n",
    "        model = models.resnet18(weights_resnet)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif backbone == \"efficientnet\":\n",
    "        model = models.efficientnet_b0(weights_efficient_net)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085024c-be67-4f81-9a9e-8d874b4ad242",
   "metadata": {},
   "source": [
    "## Implementing Patience feature so we don't need to run all the epochs if the model no longer improves\n",
    "Early stopping monitors a validation metric (usually loss). If it doesn’t improve for N consecutive epochs, training stops automatically.\n",
    "\n",
    "This prevents overfitting and saves compute — especially useful when you're iterating on models in your scientific workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eefd860-2d81-4a72-a784-2e2637ac0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            return\n",
    "\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe71ef0d-9192-4d90-82a9-5c2096ce8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# model training and val\n",
    "# ========================\n",
    "#def train_model(backbone, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, \n",
    "#                       epochs=10, batch_size=32, lr=1e-4, img_size=256, save_dir=\"checkpoints\",pretrained_backbone=None):\n",
    "def train_model(model, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, optimizer, criterion=None, scheduler=None, epochs=10, model_type=\"frozen-backbone\",\n",
    "               cb_loss=None):\n",
    "    since = time.time()\n",
    "\n",
    "    img_size = 256 \n",
    "    batch_size = 32\n",
    "    #lr = 1e-4\n",
    "    save_dir = \"checkpoints\"\n",
    "\n",
    "    # transforms: data augmentation and normalization for training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]), # imagenet normalization stats\n",
    "    ])\n",
    "\n",
    "    # datasets & dataloaders\n",
    "    ds_paths = {'train': [train_csv, train_image_dir], 'val': [val_csv, val_image_dir]}\n",
    "    image_datasets = {x: RetinaMultiLabelDataset(ds_paths[x][0], ds_paths[x][1], transform)\n",
    "                      for x in ['train', 'val']}\n",
    "\n",
    "    dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=(x =='train'), num_workers=0)\n",
    "                      for x in ['train', 'val']}\n",
    "    \n",
    "    # loss function\n",
    "    if criterion is None:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # training\n",
    "    best_val_loss = float(\"inf\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    ckpt_path = os.path.join(save_dir, f\"best_{backbone}_{model_type}.pt\")\n",
    "\n",
    "    # early stop mechanism \n",
    "    early_stopper = EarlyStopping(patience=5, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch}/{epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() # set model to training mode\n",
    "            else:\n",
    "                model.eval() # set model to evaluate mode\n",
    "\n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "\n",
    "            # iterate over data\n",
    "            #for imgs, labels in train_loader:\n",
    "            for imgs, labels in dataloaders[phase]:\n",
    "                imgs, labels = imgs.to(device), labels.to(device) # copy data and labels to gpu\n",
    "                optimizer.zero_grad() # zero the parameters gradients to avoid accumulating \n",
    "\n",
    "                # forward step\n",
    "                # track history only if in training phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(imgs)\n",
    "\n",
    "                    if cb_loss is not None:\n",
    "                        loss = cb_loss.compute_CB_loss(outputs, labels)\n",
    "                    else:\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward step + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        train_loss += loss.item() * imgs.size(0)\n",
    "                    else: \n",
    "                        val_loss += loss.item() * imgs.size(0)\n",
    "                        \n",
    "            if phase == 'train':\n",
    "                train_loss /= len(dataloaders['train'].dataset)\n",
    "                print(f\"[{backbone}] {phase}: Epoch {epoch+1}/{epochs} Train Loss: {train_loss:.4f}\")\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "            else:\n",
    "                val_loss /= len(dataloaders['val'].dataset)\n",
    "                print(f\"[{backbone}] {phase}: Epoch {epoch+1}/{epochs} Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "                # save best\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    torch.save(model.state_dict(), ckpt_path)\n",
    "                    print(f\"Saved best model for {backbone} at {ckpt_path} with val loss: {best_val_loss}\")\n",
    "\n",
    "                early_stopper(val_loss)\n",
    "                \n",
    "        if early_stopper.should_stop:\n",
    "            print(\"Patience has run out! Stopping!\")\n",
    "            break\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best eval loss: {best_val_loss:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "    model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061beef4-3b94-4dfb-bfc0-7c418da94c68",
   "metadata": {},
   "source": [
    "# Test Model Function \n",
    "#### I've copied the eval part of the training into a testing function in order to run \n",
    "#### inference on the test set with the untouched backbones as part of the first task  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d874e54b-0d3f-4be9-b5ae-dd4babb30990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataset, pretrained=True, img_size=256,  batch_size=32, num_workers=0):\n",
    "    # ========================\n",
    "    # testing\n",
    "    # ========================\n",
    "\n",
    "    # transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ])\n",
    "    \n",
    "    test_ds  = RetinaMultiLabelDataset(test_dataset, test_image_dir, transform)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            y_true.extend(labels.numpy())\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "    y_true = torch.tensor(y_true).numpy()\n",
    "    y_pred = torch.tensor(y_pred).numpy()\n",
    "\n",
    "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
    "\n",
    "    avg_f_score = 0.0\n",
    "    for i, disease in enumerate(disease_names):  #compute metrics for every disease\n",
    "        y_t = y_true[:, i]\n",
    "        y_p = y_pred[:, i]\n",
    "\n",
    "        acc = accuracy_score(y_t, y_p)\n",
    "        precision = precision_score(y_t, y_p, average=\"macro\",zero_division=0)\n",
    "        recall = recall_score(y_t, y_p, average=\"macro\",zero_division=0)\n",
    "        f1 = f1_score(y_t, y_p, average=\"macro\",zero_division=0)\n",
    "        kappa = cohen_kappa_score(y_t, y_p)\n",
    "        avg_f_score += f1\n",
    "\n",
    "        print(f\"{disease} Results [{backbone}]\")\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall   : {recall:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "        print(f\"Kappa    : {kappa:.4f}\")\n",
    "    \n",
    "    avg_f_score /= 3\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"Average F1-score : {f1:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1cf433-0374-4a8b-bb2c-abc4b9cc2c90",
   "metadata": {},
   "source": [
    "# TASK 1.1: NO FINE-TUNING\n",
    "## In this task we evaluate both backbones directly on the ODIR test set without any manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae42987-6aac-4435-ab71-ac1ee46b7e31",
   "metadata": {},
   "source": [
    "### Test-set with Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58bcb38a-d5e4-4079-93ef-f36107f3f40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\miniconda3\\envs\\llms\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [resnet18]\n",
      "Accuracy : 0.5150\n",
      "Precision: 0.5170\n",
      "Recall   : 0.5202\n",
      "F1-score : 0.4958\n",
      "Kappa    : 0.0339\n",
      "Glaucoma Results [resnet18]\n",
      "Accuracy : 0.7850\n",
      "Precision: 0.7063\n",
      "Recall   : 0.6784\n",
      "F1-score : 0.6893\n",
      "Kappa    : 0.3804\n",
      "AMD Results [resnet18]\n",
      "Accuracy : 0.7850\n",
      "Precision: 0.6305\n",
      "Recall   : 0.7597\n",
      "F1-score : 0.6472\n",
      "Kappa    : 0.3211\n"
     ]
    }
   ],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_resnet18_ep50.pt'\n",
    "backbone = 'resnet18'\n",
    "\n",
    "model = build_model('resnet18', num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "test_model(model, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af7c93-ed5f-4739-956b-34da00e16eca",
   "metadata": {},
   "source": [
    "### Test-set with efficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57e136f3-d170-43cd-9ced-9a47eaf60d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\miniconda3\\envs\\llms\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [efficientnet]\n",
      "Accuracy : 0.6000\n",
      "Precision: 0.5588\n",
      "Recall   : 0.5667\n",
      "F1-score : 0.5575\n",
      "Kappa    : 0.1228\n",
      "Glaucoma Results [efficientnet]\n",
      "Accuracy : 0.7950\n",
      "Precision: 0.7243\n",
      "Recall   : 0.7333\n",
      "F1-score : 0.7285\n",
      "Kappa    : 0.4571\n",
      "AMD Results [efficientnet]\n",
      "Accuracy : 0.7150\n",
      "Precision: 0.6041\n",
      "Recall   : 0.7403\n",
      "F1-score : 0.5946\n",
      "Kappa    : 0.2482\n"
     ]
    }
   ],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_efficientnet_ep50.pt'\n",
    "backbone = 'efficientnet'\n",
    "\n",
    "model = build_model('efficientnet', num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "test_model(model, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e419eda-c7f9-4765-9a16-40b3889da46f",
   "metadata": {},
   "source": [
    "# Task 1.2 Frozen backbone, fine-tunning classifier only \n",
    "#### In this task we'll do what's called \"Feature Extraction\", we'll freeze all the network, except the final layer. \n",
    "#### We need to set `requires_grad = False` to freeze the parameters so that the gradients are not computer in `backward()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64458a6a-5bfa-490e-ba12-1c649c99c66b",
   "metadata": {},
   "source": [
    "## Feature Extraction with Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83ee0309-8871-47e5-b2ff-6bc22ccaae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\miniconda3\\envs\\llms\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_resnet18_ep50.pt'\n",
    "backbone = 'resnet18'\n",
    "\n",
    "model_conv = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model_conv.load_state_dict(state_dict)\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# rebuilding classifier layer\n",
    "# parameters of newly contructed modules have requires_grad=True by default\n",
    "num_classes = 3\n",
    "model_conv.fc = nn.Linear(model_conv.fc.in_features, num_classes)\n",
    "\n",
    "# Only parameters of final layer are being optimized as\n",
    "optimizer = optim.Adam(model_conv.fc.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351d4e2-af16-4e46-800e-df6f7f1758cf",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b7b8df9b-f750-4c39-a199-644409f00461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "[resnet18] train: Epoch 1/25 Train Loss: 0.6760\n",
      "[resnet18] val: Epoch 1/25 Val Loss: 0.6420\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.6420445466041564\n",
      "Epoch 1/24\n",
      "----------\n",
      "[resnet18] train: Epoch 2/25 Train Loss: 0.5592\n",
      "[resnet18] val: Epoch 2/25 Val Loss: 0.6078\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.6078139472007752\n",
      "Epoch 2/24\n",
      "----------\n",
      "[resnet18] train: Epoch 3/25 Train Loss: 0.5262\n",
      "[resnet18] val: Epoch 3/25 Val Loss: 0.5920\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5919931149482727\n",
      "Epoch 3/24\n",
      "----------\n",
      "[resnet18] train: Epoch 4/25 Train Loss: 0.5131\n",
      "[resnet18] val: Epoch 4/25 Val Loss: 0.5829\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5828698968887329\n",
      "Epoch 4/24\n",
      "----------\n",
      "[resnet18] train: Epoch 5/25 Train Loss: 0.5023\n",
      "[resnet18] val: Epoch 5/25 Val Loss: 0.5734\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5733610367774964\n",
      "Epoch 5/24\n",
      "----------\n",
      "[resnet18] train: Epoch 6/25 Train Loss: 0.4955\n",
      "[resnet18] val: Epoch 6/25 Val Loss: 0.5696\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5695706629753112\n",
      "Epoch 6/24\n",
      "----------\n",
      "[resnet18] train: Epoch 7/25 Train Loss: 0.4885\n",
      "[resnet18] val: Epoch 7/25 Val Loss: 0.5660\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5659775519371033\n",
      "Epoch 7/24\n",
      "----------\n",
      "[resnet18] train: Epoch 8/25 Train Loss: 0.4845\n",
      "[resnet18] val: Epoch 8/25 Val Loss: 0.5568\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5568361282348633\n",
      "Epoch 8/24\n",
      "----------\n",
      "[resnet18] train: Epoch 9/25 Train Loss: 0.4833\n",
      "[resnet18] val: Epoch 9/25 Val Loss: 0.5556\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5556306529045105\n",
      "Epoch 9/24\n",
      "----------\n",
      "[resnet18] train: Epoch 10/25 Train Loss: 0.4802\n",
      "[resnet18] val: Epoch 10/25 Val Loss: 0.5574\n",
      "Epoch 10/24\n",
      "----------\n",
      "[resnet18] train: Epoch 11/25 Train Loss: 0.4782\n",
      "[resnet18] val: Epoch 11/25 Val Loss: 0.5487\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5487443161010742\n",
      "Epoch 11/24\n",
      "----------\n",
      "[resnet18] train: Epoch 12/25 Train Loss: 0.4765\n",
      "[resnet18] val: Epoch 12/25 Val Loss: 0.5493\n",
      "Epoch 12/24\n",
      "----------\n",
      "[resnet18] train: Epoch 13/25 Train Loss: 0.4725\n",
      "[resnet18] val: Epoch 13/25 Val Loss: 0.5478\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5478084754943847\n",
      "Epoch 13/24\n",
      "----------\n",
      "[resnet18] train: Epoch 14/25 Train Loss: 0.4713\n",
      "[resnet18] val: Epoch 14/25 Val Loss: 0.5427\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5427386569976806\n",
      "Epoch 14/24\n",
      "----------\n",
      "[resnet18] train: Epoch 15/25 Train Loss: 0.4716\n",
      "[resnet18] val: Epoch 15/25 Val Loss: 0.5424\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5423617386817932\n",
      "Epoch 15/24\n",
      "----------\n",
      "[resnet18] train: Epoch 16/25 Train Loss: 0.4673\n",
      "[resnet18] val: Epoch 16/25 Val Loss: 0.5392\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5391532373428345\n",
      "Epoch 16/24\n",
      "----------\n",
      "[resnet18] train: Epoch 17/25 Train Loss: 0.4673\n",
      "[resnet18] val: Epoch 17/25 Val Loss: 0.5375\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5374918985366821\n",
      "Epoch 17/24\n",
      "----------\n",
      "[resnet18] train: Epoch 18/25 Train Loss: 0.4696\n",
      "[resnet18] val: Epoch 18/25 Val Loss: 0.5395\n",
      "Epoch 18/24\n",
      "----------\n",
      "[resnet18] train: Epoch 19/25 Train Loss: 0.4608\n",
      "[resnet18] val: Epoch 19/25 Val Loss: 0.5378\n",
      "Epoch 19/24\n",
      "----------\n",
      "[resnet18] train: Epoch 20/25 Train Loss: 0.4647\n",
      "[resnet18] val: Epoch 20/25 Val Loss: 0.5364\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5363725352287293\n",
      "Epoch 20/24\n",
      "----------\n",
      "[resnet18] train: Epoch 21/25 Train Loss: 0.4644\n",
      "[resnet18] val: Epoch 21/25 Val Loss: 0.5310\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5309802651405334\n",
      "Epoch 21/24\n",
      "----------\n",
      "[resnet18] train: Epoch 22/25 Train Loss: 0.4596\n",
      "[resnet18] val: Epoch 22/25 Val Loss: 0.5318\n",
      "Epoch 22/24\n",
      "----------\n",
      "[resnet18] train: Epoch 23/25 Train Loss: 0.4634\n",
      "[resnet18] val: Epoch 23/25 Val Loss: 0.5353\n",
      "Epoch 23/24\n",
      "----------\n",
      "[resnet18] train: Epoch 24/25 Train Loss: 0.4611\n",
      "[resnet18] val: Epoch 24/25 Val Loss: 0.5281\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18.pt with val loss: 0.5281355667114258\n",
      "Epoch 24/24\n",
      "----------\n",
      "[resnet18] train: Epoch 25/25 Train Loss: 0.4617\n",
      "[resnet18] val: Epoch 25/25 Val Loss: 0.5318\n",
      "\n",
      "Training complete in 9m 54s\n",
      "Best eval loss: 0.528136\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, optimizer=optimizer, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e7b0f7be-5e98-48be-81f1-f01782048f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [resnet18]\n",
      "Accuracy : 0.7500\n",
      "Precision: 0.7091\n",
      "Recall   : 0.6405\n",
      "F1-score : 0.6523\n",
      "Kappa    : 0.3207\n",
      "Glaucoma Results [resnet18]\n",
      "Accuracy : 0.7700\n",
      "Precision: 0.7208\n",
      "Recall   : 0.5513\n",
      "F1-score : 0.5362\n",
      "Kappa    : 0.1416\n",
      "AMD Results [resnet18]\n",
      "Accuracy : 0.9050\n",
      "Precision: 0.8131\n",
      "Recall   : 0.6080\n",
      "F1-score : 0.6468\n",
      "Kappa    : 0.3081\n"
     ]
    }
   ],
   "source": [
    "test_model(model_conv, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56dda1-dcf4-49c5-b732-3d9b7fc7a563",
   "metadata": {},
   "source": [
    "## Feature Extraction with EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59f78f87-f82e-4071-a8a5-e5d24ed1104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\miniconda3\\envs\\llms\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_efficientnet_ep50.pt'\n",
    "backbone = 'efficientnet'\n",
    "\n",
    "model_conv_effnet = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model_conv_effnet.load_state_dict(state_dict)\n",
    "\n",
    "for param in model_conv_effnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# rebuilding classifier layer\n",
    "# parameters of newly contructed modules have requires_grad=True by default\n",
    "num_classes = 3\n",
    "model_conv_effnet.classifier[1] = nn.Linear(model_conv_effnet.classifier[1].in_features, num_classes)\n",
    "\n",
    "# Only parameters of final layer are being optimized\n",
    "optimizer = optim.Adam(model_conv_effnet.classifier[1].parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91f973-c723-489b-9633-b01f9292900a",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1611b65b-e812-4e91-977b-ee5e8ca771a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 1/25 Train Loss: 0.6259\n",
      "[efficientnet] val: Epoch 1/25 Val Loss: 0.5931\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5930671834945679\n",
      "Epoch 1/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 2/25 Train Loss: 0.5371\n",
      "[efficientnet] val: Epoch 2/25 Val Loss: 0.5663\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5662716507911683\n",
      "Epoch 2/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 3/25 Train Loss: 0.5024\n",
      "[efficientnet] val: Epoch 3/25 Val Loss: 0.5488\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5488045358657837\n",
      "Epoch 3/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 4/25 Train Loss: 0.4907\n",
      "[efficientnet] val: Epoch 4/25 Val Loss: 0.5392\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5391703486442566\n",
      "Epoch 4/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 5/25 Train Loss: 0.4670\n",
      "[efficientnet] val: Epoch 5/25 Val Loss: 0.5279\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5279150128364563\n",
      "Epoch 5/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 6/25 Train Loss: 0.4602\n",
      "[efficientnet] val: Epoch 6/25 Val Loss: 0.5195\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5195254039764404\n",
      "Epoch 6/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 7/25 Train Loss: 0.4512\n",
      "[efficientnet] val: Epoch 7/25 Val Loss: 0.5088\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5087612056732178\n",
      "Epoch 7/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 8/25 Train Loss: 0.4446\n",
      "[efficientnet] val: Epoch 8/25 Val Loss: 0.5054\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5054056119918823\n",
      "Epoch 8/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 9/25 Train Loss: 0.4353\n",
      "[efficientnet] val: Epoch 9/25 Val Loss: 0.5033\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.5033308839797974\n",
      "Epoch 9/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 10/25 Train Loss: 0.4381\n",
      "[efficientnet] val: Epoch 10/25 Val Loss: 0.5061\n",
      "Epoch 10/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 11/25 Train Loss: 0.4310\n",
      "[efficientnet] val: Epoch 11/25 Val Loss: 0.4970\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.49703250169754026\n",
      "Epoch 11/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 12/25 Train Loss: 0.4303\n",
      "[efficientnet] val: Epoch 12/25 Val Loss: 0.4990\n",
      "Epoch 12/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 13/25 Train Loss: 0.4353\n",
      "[efficientnet] val: Epoch 13/25 Val Loss: 0.4899\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.489933557510376\n",
      "Epoch 13/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 14/25 Train Loss: 0.4219\n",
      "[efficientnet] val: Epoch 14/25 Val Loss: 0.4925\n",
      "Epoch 14/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 15/25 Train Loss: 0.4238\n",
      "[efficientnet] val: Epoch 15/25 Val Loss: 0.4914\n",
      "Epoch 15/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 16/25 Train Loss: 0.4229\n",
      "[efficientnet] val: Epoch 16/25 Val Loss: 0.4913\n",
      "Epoch 16/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 17/25 Train Loss: 0.4141\n",
      "[efficientnet] val: Epoch 17/25 Val Loss: 0.4849\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.48486718654632566\n",
      "Epoch 17/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 18/25 Train Loss: 0.4174\n",
      "[efficientnet] val: Epoch 18/25 Val Loss: 0.4861\n",
      "Epoch 18/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 19/25 Train Loss: 0.4171\n",
      "[efficientnet] val: Epoch 19/25 Val Loss: 0.4810\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.48100764989852907\n",
      "Epoch 19/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 20/25 Train Loss: 0.4123\n",
      "[efficientnet] val: Epoch 20/25 Val Loss: 0.4794\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.4794058084487915\n",
      "Epoch 20/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 21/25 Train Loss: 0.4140\n",
      "[efficientnet] val: Epoch 21/25 Val Loss: 0.4821\n",
      "Epoch 21/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 22/25 Train Loss: 0.4115\n",
      "[efficientnet] val: Epoch 22/25 Val Loss: 0.4711\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet.pt with val loss: 0.47111555099487307\n",
      "Epoch 22/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 23/25 Train Loss: 0.3979\n",
      "[efficientnet] val: Epoch 23/25 Val Loss: 0.4736\n",
      "Epoch 23/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 24/25 Train Loss: 0.4028\n",
      "[efficientnet] val: Epoch 24/25 Val Loss: 0.4776\n",
      "Epoch 24/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 25/25 Train Loss: 0.4048\n",
      "[efficientnet] val: Epoch 25/25 Val Loss: 0.4747\n",
      "\n",
      "Training complete in 11m 38s\n",
      "Best eval loss: 0.471116\n"
     ]
    }
   ],
   "source": [
    "model_conv_effnet = train_model(model_conv_effnet, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, optimizer=optimizer, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "013a522f-63d0-44d1-baa9-f04337ee6911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [efficientnet]\n",
      "Accuracy : 0.7750\n",
      "Precision: 0.7385\n",
      "Recall   : 0.6917\n",
      "F1-score : 0.7058\n",
      "Kappa    : 0.4171\n",
      "Glaucoma Results [efficientnet]\n",
      "Accuracy : 0.8100\n",
      "Precision: 0.7600\n",
      "Recall   : 0.6743\n",
      "F1-score : 0.6974\n",
      "Kappa    : 0.4043\n",
      "AMD Results [efficientnet]\n",
      "Accuracy : 0.9250\n",
      "Precision: 0.8747\n",
      "Recall   : 0.6989\n",
      "F1-score : 0.7523\n",
      "Kappa    : 0.5095\n"
     ]
    }
   ],
   "source": [
    "test_model(model_conv_effnet, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5073c64-8ca6-47fd-a2dd-972f67973a43",
   "metadata": {},
   "source": [
    "# Task 1.3 Full Fine-tuning: Both backbone and classifier are updated on ODIR training set \n",
    "#### We'll load the pretrained models, resetting the final fully connected layer\n",
    "#### as the network is trained, the weights are modified during backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd578e-f5ea-4be3-8c1f-836ef0c294b7",
   "metadata": {},
   "source": [
    "## Fine-tuning Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e609852b-b4e3-4c56-9600-abea9da181a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_resnet18_ep50.pt'\n",
    "backbone = 'resnet18'\n",
    "\n",
    "model_ft_resnet = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model_ft_resnet.load_state_dict(state_dict)\n",
    "\n",
    "for p in model_ft_resnet.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_ft_resnet.parameters()), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80a606-6c18-4b6e-b180-d89ff2d24acb",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a4fb86-fb13-4c39-8cf5-ad4711cffc24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "[resnet18] train: Epoch 1/25 Train Loss: 0.8100\n",
      "[resnet18] val: Epoch 1/25 Val Loss: 0.6989\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_fine_tune.pt with val loss: 0.6988784217834473\n",
      "Epoch 1/24\n",
      "----------\n",
      "[resnet18] train: Epoch 2/25 Train Loss: 0.2874\n",
      "[resnet18] val: Epoch 2/25 Val Loss: 0.5162\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_fine_tune.pt with val loss: 0.5162098836898804\n",
      "Epoch 2/24\n",
      "----------\n",
      "[resnet18] train: Epoch 3/25 Train Loss: 0.1737\n",
      "[resnet18] val: Epoch 3/25 Val Loss: 0.4896\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_fine_tune.pt with val loss: 0.48957729935646055\n",
      "Epoch 3/24\n",
      "----------\n",
      "[resnet18] train: Epoch 4/25 Train Loss: 0.0805\n",
      "[resnet18] val: Epoch 4/25 Val Loss: 0.5275\n",
      "Epoch 4/24\n",
      "----------\n",
      "[resnet18] train: Epoch 5/25 Train Loss: 0.0455\n",
      "[resnet18] val: Epoch 5/25 Val Loss: 0.5222\n",
      "Epoch 5/24\n",
      "----------\n",
      "[resnet18] train: Epoch 6/25 Train Loss: 0.0285\n",
      "[resnet18] val: Epoch 6/25 Val Loss: 0.5201\n",
      "Epoch 6/24\n",
      "----------\n",
      "[resnet18] train: Epoch 7/25 Train Loss: 0.0214\n",
      "[resnet18] val: Epoch 7/25 Val Loss: 0.5268\n",
      "Epoch 7/24\n",
      "----------\n",
      "[resnet18] train: Epoch 8/25 Train Loss: 0.0163\n",
      "[resnet18] val: Epoch 8/25 Val Loss: 0.5627\n",
      "Epoch 8/24\n",
      "----------\n",
      "[resnet18] train: Epoch 9/25 Train Loss: 0.0114\n",
      "[resnet18] val: Epoch 9/25 Val Loss: 0.5695\n",
      "Epoch 9/24\n",
      "----------\n",
      "[resnet18] train: Epoch 10/25 Train Loss: 0.0094\n",
      "[resnet18] val: Epoch 10/25 Val Loss: 0.5442\n",
      "Epoch 10/24\n",
      "----------\n",
      "[resnet18] train: Epoch 11/25 Train Loss: 0.0066\n",
      "[resnet18] val: Epoch 11/25 Val Loss: 0.5647\n",
      "Epoch 11/24\n",
      "----------\n",
      "[resnet18] train: Epoch 12/25 Train Loss: 0.0056\n",
      "[resnet18] val: Epoch 12/25 Val Loss: 0.5411\n",
      "Epoch 12/24\n",
      "----------\n",
      "[resnet18] train: Epoch 13/25 Train Loss: 0.0059\n",
      "[resnet18] val: Epoch 13/25 Val Loss: 0.5557\n",
      "Epoch 13/24\n",
      "----------\n",
      "[resnet18] train: Epoch 14/25 Train Loss: 0.0056\n",
      "[resnet18] val: Epoch 14/25 Val Loss: 0.5821\n",
      "Epoch 14/24\n",
      "----------\n",
      "[resnet18] train: Epoch 15/25 Train Loss: 0.0049\n",
      "[resnet18] val: Epoch 15/25 Val Loss: 0.5698\n",
      "Epoch 15/24\n",
      "----------\n",
      "[resnet18] train: Epoch 16/25 Train Loss: 0.0047\n",
      "[resnet18] val: Epoch 16/25 Val Loss: 0.5784\n",
      "Epoch 16/24\n",
      "----------\n",
      "[resnet18] train: Epoch 17/25 Train Loss: 0.0039\n",
      "[resnet18] val: Epoch 17/25 Val Loss: 0.5584\n",
      "Epoch 17/24\n",
      "----------\n",
      "[resnet18] train: Epoch 18/25 Train Loss: 0.0029\n",
      "[resnet18] val: Epoch 18/25 Val Loss: 0.5564\n",
      "Epoch 18/24\n",
      "----------\n",
      "[resnet18] train: Epoch 19/25 Train Loss: 0.0039\n",
      "[resnet18] val: Epoch 19/25 Val Loss: 0.6025\n",
      "Epoch 19/24\n",
      "----------\n",
      "[resnet18] train: Epoch 20/25 Train Loss: 0.0063\n",
      "[resnet18] val: Epoch 20/25 Val Loss: 0.6074\n",
      "Epoch 20/24\n",
      "----------\n",
      "[resnet18] train: Epoch 21/25 Train Loss: 0.0026\n",
      "[resnet18] val: Epoch 21/25 Val Loss: 0.5970\n",
      "Epoch 21/24\n",
      "----------\n",
      "[resnet18] train: Epoch 22/25 Train Loss: 0.0029\n",
      "[resnet18] val: Epoch 22/25 Val Loss: 0.6272\n",
      "Epoch 22/24\n",
      "----------\n",
      "[resnet18] train: Epoch 23/25 Train Loss: 0.0032\n",
      "[resnet18] val: Epoch 23/25 Val Loss: 0.5932\n",
      "Epoch 23/24\n",
      "----------\n",
      "[resnet18] train: Epoch 24/25 Train Loss: 0.0034\n",
      "[resnet18] val: Epoch 24/25 Val Loss: 0.6006\n",
      "Epoch 24/24\n",
      "----------\n",
      "[resnet18] train: Epoch 25/25 Train Loss: 0.0020\n",
      "[resnet18] val: Epoch 25/25 Val Loss: 0.6513\n",
      "\n",
      "Training complete in 22m 14s\n",
      "Best eval loss: 0.489577\n"
     ]
    }
   ],
   "source": [
    "model_ft_resnet = train_model(model_ft_resnet, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, optimizer=optimizer, epochs=25, model_type=\"fine_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a0211a2-31c6-4b7b-a77a-6f5a808e7524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [resnet18]\n",
      "Accuracy : 0.8150\n",
      "Precision: 0.7809\n",
      "Recall   : 0.7726\n",
      "F1-score : 0.7765\n",
      "Kappa    : 0.5531\n",
      "Glaucoma Results [resnet18]\n",
      "Accuracy : 0.8900\n",
      "Precision: 0.8803\n",
      "Recall   : 0.8100\n",
      "F1-score : 0.8371\n",
      "Kappa    : 0.6759\n",
      "AMD Results [resnet18]\n",
      "Accuracy : 0.9350\n",
      "Precision: 0.8730\n",
      "Recall   : 0.7643\n",
      "F1-score : 0.8064\n",
      "Kappa    : 0.6142\n",
      "----------\n",
      "Average F1-score : 0.8064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\AppData\\Local\\Temp\\ipykernel_22256\\4137734398.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  y_true = torch.tensor(y_true).numpy()\n"
     ]
    }
   ],
   "source": [
    "test_model(model_ft_resnet, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f7eba-7a31-416c-abe7-6fbb59736339",
   "metadata": {},
   "source": [
    "## Fine Tuning EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "212bbca0-be0a-41c1-99d0-453757c1b864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\miniconda3\\envs\\llms\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_efficientnet_ep50.pt'\n",
    "backbone = 'efficientnet'\n",
    "\n",
    "model_ft_effnet = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model_ft_effnet.load_state_dict(state_dict)\n",
    "\n",
    "for p in model_ft_effnet.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_ft_effnet.parameters()), lr=1e-3)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs (model was not anymore learning after 5 epoch on full fine tuning)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65bcea-9715-48f7-939e-6499570b5742",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1235987a-1e36-4a8c-af6d-2b044793c687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 1/25 Train Loss: 0.5473\n",
      "[efficientnet] val: Epoch 1/25 Val Loss: 0.4415\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet_fine_tune.pt with val loss: 0.44152442216873167\n",
      "Epoch 1/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 2/25 Train Loss: 0.2281\n",
      "[efficientnet] val: Epoch 2/25 Val Loss: 0.7603\n",
      "Epoch 2/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 3/25 Train Loss: 0.1249\n",
      "[efficientnet] val: Epoch 3/25 Val Loss: 0.5108\n",
      "Epoch 3/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 4/25 Train Loss: 0.0950\n",
      "[efficientnet] val: Epoch 4/25 Val Loss: 0.6312\n",
      "Epoch 4/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 5/25 Train Loss: 0.1030\n",
      "[efficientnet] val: Epoch 5/25 Val Loss: 0.7067\n",
      "Epoch 5/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 6/25 Train Loss: 0.0984\n",
      "[efficientnet] val: Epoch 6/25 Val Loss: 0.6420\n",
      "Epoch 6/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 7/25 Train Loss: 0.0838\n",
      "[efficientnet] val: Epoch 7/25 Val Loss: 0.5184\n",
      "Epoch 7/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 8/25 Train Loss: 0.0508\n",
      "[efficientnet] val: Epoch 8/25 Val Loss: 0.6523\n",
      "Epoch 8/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 9/25 Train Loss: 0.0271\n",
      "[efficientnet] val: Epoch 9/25 Val Loss: 0.6686\n",
      "Epoch 9/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 10/25 Train Loss: 0.0350\n",
      "[efficientnet] val: Epoch 10/25 Val Loss: 0.7780\n",
      "Epoch 10/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 11/25 Train Loss: 0.0245\n",
      "[efficientnet] val: Epoch 11/25 Val Loss: 0.7078\n",
      "Epoch 11/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 12/25 Train Loss: 0.0251\n",
      "[efficientnet] val: Epoch 12/25 Val Loss: 0.7122\n",
      "Epoch 12/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 13/25 Train Loss: 0.0221\n",
      "[efficientnet] val: Epoch 13/25 Val Loss: 0.6665\n",
      "Epoch 13/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 14/25 Train Loss: 0.0168\n",
      "[efficientnet] val: Epoch 14/25 Val Loss: 0.6300\n",
      "Epoch 14/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 15/25 Train Loss: 0.0172\n",
      "[efficientnet] val: Epoch 15/25 Val Loss: 0.6810\n",
      "Epoch 15/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 16/25 Train Loss: 0.0175\n",
      "[efficientnet] val: Epoch 16/25 Val Loss: 0.6784\n",
      "Epoch 16/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 17/25 Train Loss: 0.0174\n",
      "[efficientnet] val: Epoch 17/25 Val Loss: 0.7044\n",
      "Epoch 17/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 18/25 Train Loss: 0.0164\n",
      "[efficientnet] val: Epoch 18/25 Val Loss: 0.6845\n",
      "Epoch 18/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 19/25 Train Loss: 0.0158\n",
      "[efficientnet] val: Epoch 19/25 Val Loss: 0.6830\n",
      "Epoch 19/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 20/25 Train Loss: 0.0132\n",
      "[efficientnet] val: Epoch 20/25 Val Loss: 0.6378\n",
      "Epoch 20/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 21/25 Train Loss: 0.0144\n",
      "[efficientnet] val: Epoch 21/25 Val Loss: 0.6435\n",
      "Epoch 21/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 22/25 Train Loss: 0.0154\n",
      "[efficientnet] val: Epoch 22/25 Val Loss: 0.6521\n",
      "Epoch 22/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 23/25 Train Loss: 0.0149\n",
      "[efficientnet] val: Epoch 23/25 Val Loss: 0.6618\n",
      "Epoch 23/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 24/25 Train Loss: 0.0121\n",
      "[efficientnet] val: Epoch 24/25 Val Loss: 0.6987\n",
      "Epoch 24/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 25/25 Train Loss: 0.0183\n",
      "[efficientnet] val: Epoch 25/25 Val Loss: 0.6670\n",
      "\n",
      "Training complete in 30m 51s\n",
      "Best eval loss: 0.441524\n"
     ]
    }
   ],
   "source": [
    "model_ft_effnet = train_model(model_ft_effnet, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, scheduler=scheduler,\n",
    "                                optimizer=optimizer, epochs=25, model_type=\"fine_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa34fa1c-6400-4547-81d3-2eaa440dd0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [efficientnet]\n",
      "Accuracy : 0.7600\n",
      "Precision: 0.7270\n",
      "Recall   : 0.7571\n",
      "F1-score : 0.7345\n",
      "Kappa    : 0.4737\n",
      "Glaucoma Results [efficientnet]\n",
      "Accuracy : 0.8700\n",
      "Precision: 0.8704\n",
      "Recall   : 0.7623\n",
      "F1-score : 0.7969\n",
      "Kappa    : 0.5988\n",
      "AMD Results [efficientnet]\n",
      "Accuracy : 0.8600\n",
      "Precision: 0.6763\n",
      "Recall   : 0.7421\n",
      "F1-score : 0.7003\n",
      "Kappa    : 0.4037\n",
      "----------\n",
      "Average F1-score : 0.7003\n"
     ]
    }
   ],
   "source": [
    "test_model(model_ft_effnet, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc8498-5be4-4546-ad39-a9e2e6db65aa",
   "metadata": {},
   "source": [
    "# Task 2.1: Implementing a Focal Loss function\n",
    "## Focal Loss is a powerful technical for dealing with class imbalance by focusing training on hard, misclassified examples.\n",
    "\n",
    "##### Focal Loss adds a modulating factor to cross‑entropy so that easy \n",
    "##### examples are down‑weighted and hard examples get more focus. \n",
    "##### This is widely used in object detection models like RetinaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15d1fb-bfb0-4f38-b53a-0674cc7cfa3b",
   "metadata": {},
   "source": [
    "## Implementing Focal Loss in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e580296d-bedc-4b7c-a777-292cc08003c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=0.25, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        \"\"\"\n",
    "        :param gamma: Focusing parameter, controls the strength of the modulating factor (1 - p_t)^gamma\n",
    "        :param alpha: Balancing factor, can be a scalar or a tensor for class-wise weights. If None, no class balancing is used.\n",
    "        :param reduction: Specifies the reduction method: 'none' | 'mean' | 'sum'\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\" Focal Loss for Multi-label classification \"\"\"\n",
    "        \"\"\"\n",
    "        inputs: tensor of shape (batch, num_classes)\n",
    "        targets: tensor of shape (batch, num_classes) with 0/1 labels\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(inputs)\n",
    "\n",
    "        # Compute binary cross entropy\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "\n",
    "        # compute focal weight\n",
    "        pt = probs * targets + (1 - probs) * (1 - targets)\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "\n",
    "        # apply alpha if provided\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "            bce_loss = alpha_t * bce_loss\n",
    "\n",
    "        # apply focal loss weight\n",
    "        loss = focal_weight * bce_loss\n",
    " \n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffebc65-383f-48fd-9d24-e9b843683ed5",
   "metadata": {},
   "source": [
    "## Fine tuning resnet18 with Focal Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76c24773-a95c-4186-97c7-540376881761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\miniconda3\\envs\\llms\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_resnet18_ep50.pt'\n",
    "backbone = 'resnet18'\n",
    "\n",
    "model_fc_ft_resnet = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model_fc_ft_resnet.load_state_dict(state_dict)\n",
    "for p in model_fc_ft_resnet.parameters():\n",
    "        p.requires_grad = True\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_fc_ft_resnet.parameters()), lr=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Loss function using Focal Loss method\n",
    "criterion = FocalLoss(alpha=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f29f7d9-e1ef-4a99-b8cd-0dc1e95a951d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "[resnet18] train: Epoch 1/25 Train Loss: 0.6603\n",
      "[resnet18] val: Epoch 1/25 Val Loss: 0.5030\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_focal_loss_fine_tuned.pt with val loss: 0.5030284738540649\n",
      "Epoch 1/24\n",
      "----------\n",
      "[resnet18] train: Epoch 2/25 Train Loss: 0.1288\n",
      "[resnet18] val: Epoch 2/25 Val Loss: 0.2917\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_focal_loss_fine_tuned.pt with val loss: 0.2916832408308983\n",
      "Epoch 2/24\n",
      "----------\n",
      "[resnet18] train: Epoch 3/25 Train Loss: 0.0683\n",
      "[resnet18] val: Epoch 3/25 Val Loss: 0.2621\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_focal_loss_fine_tuned.pt with val loss: 0.26209314823150637\n",
      "Epoch 3/24\n",
      "----------\n",
      "[resnet18] train: Epoch 4/25 Train Loss: 0.0467\n",
      "[resnet18] val: Epoch 4/25 Val Loss: 0.2265\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_focal_loss_fine_tuned.pt with val loss: 0.22646843910217285\n",
      "Epoch 4/24\n",
      "----------\n",
      "[resnet18] train: Epoch 5/25 Train Loss: 0.0278\n",
      "[resnet18] val: Epoch 5/25 Val Loss: 0.2564\n",
      "Epoch 5/24\n",
      "----------\n",
      "[resnet18] train: Epoch 6/25 Train Loss: 0.0130\n",
      "[resnet18] val: Epoch 6/25 Val Loss: 0.2570\n",
      "Epoch 6/24\n",
      "----------\n",
      "[resnet18] train: Epoch 7/25 Train Loss: 0.0100\n",
      "[resnet18] val: Epoch 7/25 Val Loss: 0.2506\n",
      "Epoch 7/24\n",
      "----------\n",
      "[resnet18] train: Epoch 8/25 Train Loss: 0.0063\n",
      "[resnet18] val: Epoch 8/25 Val Loss: 0.2782\n",
      "Epoch 8/24\n",
      "----------\n",
      "[resnet18] train: Epoch 9/25 Train Loss: 0.0066\n",
      "[resnet18] val: Epoch 9/25 Val Loss: 0.2930\n",
      "Patience has run out! Stopping!\n",
      "\n",
      "Training complete in 8m 3s\n",
      "Best eval loss: 0.226468\n"
     ]
    }
   ],
   "source": [
    "model_ft_effnet = train_model(model_fc_ft_resnet, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, scheduler=scheduler,\n",
    "                                criterion=criterion, optimizer=optimizer, epochs=25, model_type=\"focal_loss_fine_tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e2c34-900d-4b44-9117-74ca95ef66d3",
   "metadata": {},
   "source": [
    "## Testing trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e7edd52-0c67-44c3-85a2-c802c7bff3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [resnet18]\n",
      "Accuracy : 0.7900\n",
      "Precision: 0.7510\n",
      "Recall   : 0.7643\n",
      "F1-score : 0.7567\n",
      "Kappa    : 0.5139\n",
      "Glaucoma Results [resnet18]\n",
      "Accuracy : 0.8850\n",
      "Precision: 0.8686\n",
      "Recall   : 0.8067\n",
      "F1-score : 0.8311\n",
      "Kappa    : 0.6636\n",
      "AMD Results [resnet18]\n",
      "Accuracy : 0.9050\n",
      "Precision: 0.7578\n",
      "Recall   : 0.7474\n",
      "F1-score : 0.7525\n",
      "Kappa    : 0.5050\n",
      "----------\n",
      "Average F1-score : 0.7525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\AppData\\Local\\Temp\\ipykernel_15480\\4137734398.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  y_true = torch.tensor(y_true).numpy()\n"
     ]
    }
   ],
   "source": [
    "test_model(model_fc_ft_resnet, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad9ca4d-4b5e-4176-9a65-e2a0e8c9bbe0",
   "metadata": {},
   "source": [
    "## Fine tuning EfficientNet with Focal Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf750384-9095-46f7-a313-cfeb77d2d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_efficientnet_ep50.pt'\n",
    "backbone = 'efficientnet'\n",
    "\n",
    "model_fc_ft_effnet = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model_fc_ft_effnet.load_state_dict(state_dict)\n",
    "for p in model_fc_ft_effnet.parameters():\n",
    "        p.requires_grad = True\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_fc_ft_effnet.parameters()), lr=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Loss function using Focal Loss method\n",
    "criterion = FocalLoss(alpha=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0454b9cc-2ceb-42b4-9ab1-5b31cc252496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 1/25 Train Loss: 0.8610\n",
      "[efficientnet] val: Epoch 1/25 Val Loss: 0.5453\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet_focal_loss_fine_tuned.pt with val loss: 0.5452643358707427\n",
      "Epoch 1/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 2/25 Train Loss: 0.2387\n",
      "[efficientnet] val: Epoch 2/25 Val Loss: 0.3134\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet_focal_loss_fine_tuned.pt with val loss: 0.31337508678436277\n",
      "Epoch 2/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 3/25 Train Loss: 0.1025\n",
      "[efficientnet] val: Epoch 3/25 Val Loss: 0.2726\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet_focal_loss_fine_tuned.pt with val loss: 0.272551486492157\n",
      "Epoch 3/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 4/25 Train Loss: 0.0722\n",
      "[efficientnet] val: Epoch 4/25 Val Loss: 0.2394\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet_focal_loss_fine_tuned.pt with val loss: 0.23936595916748046\n",
      "Epoch 4/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 5/25 Train Loss: 0.0498\n",
      "[efficientnet] val: Epoch 5/25 Val Loss: 0.2453\n",
      "Epoch 5/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 6/25 Train Loss: 0.0385\n",
      "[efficientnet] val: Epoch 6/25 Val Loss: 0.2465\n",
      "Epoch 6/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 7/25 Train Loss: 0.0315\n",
      "[efficientnet] val: Epoch 7/25 Val Loss: 0.2409\n",
      "Epoch 7/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 8/25 Train Loss: 0.0271\n",
      "[efficientnet] val: Epoch 8/25 Val Loss: 0.2467\n",
      "Epoch 8/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 9/25 Train Loss: 0.0256\n",
      "[efficientnet] val: Epoch 9/25 Val Loss: 0.2416\n",
      "Patience has run out! Stopping!\n",
      "\n",
      "Training complete in 11m 19s\n",
      "Best eval loss: 0.239366\n"
     ]
    }
   ],
   "source": [
    "model_fc_ft_effnet = train_model(model_fc_ft_effnet, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, scheduler=scheduler,\n",
    "                                criterion=criterion, optimizer=optimizer, epochs=25, model_type=\"focal_loss_fine_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc3f11b4-5ad7-4477-860a-11c942386b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [efficientnet]\n",
      "Accuracy : 0.7400\n",
      "Precision: 0.7016\n",
      "Recall   : 0.7238\n",
      "F1-score : 0.7082\n",
      "Kappa    : 0.4196\n",
      "Glaucoma Results [efficientnet]\n",
      "Accuracy : 0.8150\n",
      "Precision: 0.7509\n",
      "Recall   : 0.7327\n",
      "F1-score : 0.7408\n",
      "Kappa    : 0.4821\n",
      "AMD Results [efficientnet]\n",
      "Accuracy : 0.8550\n",
      "Precision: 0.6758\n",
      "Recall   : 0.7592\n",
      "F1-score : 0.7033\n",
      "Kappa    : 0.4118\n",
      "----------\n",
      "Average F1-score : 0.7033\n"
     ]
    }
   ],
   "source": [
    "test_model(model_fc_ft_effnet, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a220d0-8574-4b2b-9686-482530ebc5f3",
   "metadata": {},
   "source": [
    "# Task 2.2: Class-Balanced Loss\n",
    "Class‑Balanced Loss (CB Loss) is a principled way to correct for class imbalance by re‑weighting each class according to its effective number of samples, rather than raw counts. It is widely used in deep learning tasks where minority classes would otherwise be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e3333-d770-44c6-b63f-481f0f5edeff",
   "metadata": {},
   "source": [
    "## Implementing CB Loss in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a40b0c92-2795-43ed-944e-b925cf144412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class CB_Loss():\n",
    "    def __init__(self, samples_per_cls, no_of_classes, beta, gamma):\n",
    "        self.samples_per_cls = samples_per_cls\n",
    "        self.no_of_classes = no_of_classes\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def compute_CB_loss(self, logits, labels):\n",
    "        \"\"\"Compute the Class Balanced Loss between `logits` and the ground truth `labels`.\n",
    "    \n",
    "        Class Balanced Loss: ((1-beta)/(1-beta^n))*Loss(labels, logits)\n",
    "        where Loss is one of the standard losses used for Neural Networks.\n",
    "    \n",
    "        Args:\n",
    "          labels: A int tensor of size [batch].  (targets)\n",
    "          logits: A float tensor of size [batch, no_of_classes]. (inputs)\n",
    "          samples_per_cls: A python list of size [no_of_classes]. Number of training samples belonging to each class.\n",
    "          no_of_classes: total number of classes. int\n",
    "          loss_type: string. One of \"sigmoid\", \"focal\", \"softmax\".\n",
    "          beta: float. Hyperparameter for Class balanced loss.\n",
    "          gamma: float. Hyperparameter for Focal loss.\n",
    "    \n",
    "        Returns:\n",
    "          cb_loss: A float tensor representing class balanced loss\n",
    "        \"\"\"\n",
    "        # Compute effective number for each class\n",
    "        effective_num = 1.0 - torch.pow(self.beta, self.samples_per_cls)\n",
    "        weights = (1.0 - self.beta) / effective_num\n",
    "    \n",
    "        # Normalize weights so they sum to num_classes\n",
    "        weights = weights / torch.sum(weights) * self.no_of_classes\n",
    "    \n",
    "        #labels_one_hot = F.one_hot(labels, self.no_of_classes).float()\n",
    "    \n",
    "        #weights = torch.tensor(weights).float()\n",
    "    \n",
    "        # Reshape for broadcasting: (1, num_classes)\n",
    "        weights = weights.unsqueeze(0)\n",
    "        #weights = weights.repeat(labels_one_hot.shape[0],1) * labels_one_hot\n",
    "        #weights = weights.sum(1)\n",
    "        #weights = weights.unsqueeze(1)\n",
    "        #weights = weights.repeat(1, self.no_of_classes)\n",
    "    \n",
    "        # cb loss for multi-label classficiation\n",
    "        bce = F.binary_cross_entropy_with_logits(input = logits,target = labels, reduction='none')\n",
    "\n",
    "        # apply class-balanced weights\n",
    "        cb_loss = bce * weights\n",
    "        \n",
    "        return cb_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab2b89-d6c7-46c7-bbf2-c4514b1ccb41",
   "metadata": {},
   "source": [
    "## Fine tuning resnet18 with CB Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbe811b0-6165-4bf2-a0be-5b269744e922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\miniconda3\\envs\\llms\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_resnet18_ep50.pt'\n",
    "backbone = 'resnet18'\n",
    "\n",
    "model_cb_ft_resnet = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model_cb_ft_resnet.load_state_dict(state_dict)\n",
    "for p in model_cb_ft_resnet.parameters():\n",
    "        p.requires_grad = True\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_cb_ft_resnet.parameters()), lr=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# setting up of Class Balanced Loss method\n",
    "no_classes = 3\n",
    "samples_per_class = torch.tensor([517, 163, 142]) # DR, Glaucoma, AMD - as stated in the project pdf (which I'll just blindly trust)\n",
    "CB_loss = CB_Loss(samples_per_cls=samples_per_class, no_of_classes=no_classes, beta=0.9999, gamma=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f502600-2037-4234-b771-1d017b722474",
   "metadata": {},
   "source": [
    "## Training and testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70ff0ee3-674f-4f3e-a899-df6443d38db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "[resnet18] train: Epoch 1/25 Train Loss: 0.6130\n",
      "[resnet18] val: Epoch 1/25 Val Loss: 0.5831\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_class_balance_fine_tuned.pt with val loss: 0.5831085252761841\n",
      "Epoch 1/24\n",
      "----------\n",
      "[resnet18] train: Epoch 2/25 Train Loss: 0.2520\n",
      "[resnet18] val: Epoch 2/25 Val Loss: 0.4343\n",
      "Saved best model for resnet18 at checkpoints\\best_resnet18_class_balance_fine_tuned.pt with val loss: 0.4343432652950287\n",
      "Epoch 2/24\n",
      "----------\n",
      "[resnet18] train: Epoch 3/25 Train Loss: 0.1322\n",
      "[resnet18] val: Epoch 3/25 Val Loss: 0.4721\n",
      "Epoch 3/24\n",
      "----------\n",
      "[resnet18] train: Epoch 4/25 Train Loss: 0.0707\n",
      "[resnet18] val: Epoch 4/25 Val Loss: 0.4428\n",
      "Epoch 4/24\n",
      "----------\n",
      "[resnet18] train: Epoch 5/25 Train Loss: 0.0291\n",
      "[resnet18] val: Epoch 5/25 Val Loss: 0.4503\n",
      "Epoch 5/24\n",
      "----------\n",
      "[resnet18] train: Epoch 6/25 Train Loss: 0.0197\n",
      "[resnet18] val: Epoch 6/25 Val Loss: 0.4577\n",
      "Epoch 6/24\n",
      "----------\n",
      "[resnet18] train: Epoch 7/25 Train Loss: 0.0138\n",
      "[resnet18] val: Epoch 7/25 Val Loss: 0.4783\n",
      "Patience has run out! Stopping!\n",
      "\n",
      "Training complete in 5m 55s\n",
      "Best eval loss: 0.434343\n"
     ]
    }
   ],
   "source": [
    "model_cb_ft_resnet = train_model(model_cb_ft_resnet, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, scheduler=scheduler,\n",
    "                                criterion=None, optimizer=optimizer, epochs=25, model_type=\"class_balance_fine_tuned\", cb_loss=CB_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f16cd165-c394-497f-9760-c700153fe240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [resnet18]\n",
      "Accuracy : 0.8100\n",
      "Precision: 0.7735\n",
      "Recall   : 0.7786\n",
      "F1-score : 0.7759\n",
      "Kappa    : 0.5519\n",
      "Glaucoma Results [resnet18]\n",
      "Accuracy : 0.8750\n",
      "Precision: 0.8469\n",
      "Recall   : 0.8000\n",
      "F1-score : 0.8194\n",
      "Kappa    : 0.6398\n",
      "AMD Results [resnet18]\n",
      "Accuracy : 0.9200\n",
      "Precision: 0.8139\n",
      "Recall   : 0.7360\n",
      "F1-score : 0.7674\n",
      "Kappa    : 0.5360\n",
      "----------\n",
      "Average F1-score : 0.7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\AppData\\Local\\Temp\\ipykernel_32288\\4137734398.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  y_true = torch.tensor(y_true).numpy()\n"
     ]
    }
   ],
   "source": [
    "test_model(model_cb_ft_resnet, test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2cdf7a-236f-458d-aad5-45069c291a0d",
   "metadata": {},
   "source": [
    "## Fine tuning efficientNet with CB Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc157425-ef2f-4d75-ba4f-4907488f1bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\netos\\miniconda3\\envs\\llms\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pretrained_backbone = './pretrained_backbone/ckpt_efficientnet_ep50.pt'\n",
    "backbone = 'efficientnet'\n",
    "\n",
    "model_cb_ft_effnet = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
    "state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
    "model_cb_ft_effnet.load_state_dict(state_dict)\n",
    "for p in model_cb_ft_effnet.parameters():\n",
    "        p.requires_grad = True\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_cb_ft_effnet.parameters()), lr=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# setting up of Class Balanced Loss method\n",
    "no_classes = 3\n",
    "samples_per_class = torch.tensor([517, 163, 142]) # DR, Glaucoma, AMD - as stated in the project pdf (which I'll just blindly trust)\n",
    "CB_loss = CB_Loss(samples_per_cls=samples_per_class, no_of_classes=no_classes, beta=0.9999, gamma=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfe667-cabe-48ec-8264-f7eb0640e4b9",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6a8ccac-7d9f-401e-92cd-78ae4e1b6d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 1/25 Train Loss: 0.6401\n",
      "[efficientnet] val: Epoch 1/25 Val Loss: 0.5659\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet_class_balance_fine_tuned.pt with val loss: 0.5659163689613342\n",
      "Epoch 1/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 2/25 Train Loss: 0.3261\n",
      "[efficientnet] val: Epoch 2/25 Val Loss: 0.4846\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet_class_balance_fine_tuned.pt with val loss: 0.48459234952926633\n",
      "Epoch 2/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 3/25 Train Loss: 0.1970\n",
      "[efficientnet] val: Epoch 3/25 Val Loss: 0.4560\n",
      "Saved best model for efficientnet at checkpoints\\best_efficientnet_class_balance_fine_tuned.pt with val loss: 0.45597842454910276\n",
      "Epoch 3/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 4/25 Train Loss: 0.1360\n",
      "[efficientnet] val: Epoch 4/25 Val Loss: 0.4775\n",
      "Epoch 4/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 5/25 Train Loss: 0.1050\n",
      "[efficientnet] val: Epoch 5/25 Val Loss: 0.4876\n",
      "Epoch 5/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 6/25 Train Loss: 0.0689\n",
      "[efficientnet] val: Epoch 6/25 Val Loss: 0.4793\n",
      "Epoch 6/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 7/25 Train Loss: 0.0635\n",
      "[efficientnet] val: Epoch 7/25 Val Loss: 0.4925\n",
      "Epoch 7/24\n",
      "----------\n",
      "[efficientnet] train: Epoch 8/25 Train Loss: 0.0481\n",
      "[efficientnet] val: Epoch 8/25 Val Loss: 0.4960\n",
      "Patience has run out! Stopping!\n",
      "\n",
      "Training complete in 9m 18s\n",
      "Best eval loss: 0.455978\n"
     ]
    }
   ],
   "source": [
    "model_cb_ft_effnet = train_model(model_cb_ft_effnet, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir, scheduler=scheduler,\n",
    "                                criterion=None, optimizer=optimizer, epochs=25, model_type=\"class_balance_fine_tuned\", cb_loss=CB_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34ec5c13-e94f-4161-b194-b56bcf5843c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Results [efficientnet]\n",
      "Accuracy : 0.7250\n",
      "Precision: 0.6890\n",
      "Recall   : 0.7131\n",
      "F1-score : 0.6947\n",
      "Kappa    : 0.3943\n",
      "Glaucoma Results [efficientnet]\n",
      "Accuracy : 0.8500\n",
      "Precision: 0.8061\n",
      "Recall   : 0.7697\n",
      "F1-score : 0.7849\n",
      "Kappa    : 0.5709\n",
      "AMD Results [efficientnet]\n",
      "Accuracy : 0.8900\n",
      "Precision: 0.7241\n",
      "Recall   : 0.7589\n",
      "F1-score : 0.7396\n",
      "Kappa    : 0.4797\n",
      "----------\n",
      "Average F1-score : 0.7396\n"
     ]
    }
   ],
   "source": [
    "test_model(model_cb_ft_effnet, test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a6c59e-bae3-43ee-96b8-8ca0d4ac2624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
